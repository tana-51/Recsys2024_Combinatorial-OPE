#main_n_unique_actions_opl

num_runs : 100
epoch : 30
num_data : 2000
num_unique_actions_list  : [6,7,8,9,10]


dim_context : 5

reward_type : "continuous"
random_state : 12345


n_rounds_test_bandit_data : 10000 #100000

reward_std : 3.0
beta : -0.5
lambda_ : 0.8
true_element : [0,1,2]
q_hat_scale : 0.5

eps : 0.2
n_users : 200
n_optimize : 30
bias_noise_std : 2.5